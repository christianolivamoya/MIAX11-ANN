{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KoFZV1kBZkAi"
   },
   "source": [
    "<font color=\"#CA3532\"><h1 align=\"left\">Inteligencia Artificial Aplicada a la Bolsa (MIAX-11)</h1></font>\n",
    "<font color=\"#5b5a59\"><h2 align=\"left\">Extensión del modelo de regresión lineal a una dimensión arbitraria</h2></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "74sT4NIPYtiy"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GkQ5ae7LZ-zc"
   },
   "source": [
    "Generación de los datos del problema:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 562
    },
    "executionInfo": {
     "elapsed": 1613,
     "status": "ok",
     "timestamp": 1684484199835,
     "user": {
      "displayName": "christian oliva moya",
      "userId": "04396812984644697862"
     },
     "user_tz": -120
    },
    "id": "3__RYeMyZyEg",
    "outputId": "e5d7fb81-6e83-44d5-f9d5-793fc51af809"
   },
   "outputs": [],
   "source": [
    "# Parametros:\n",
    "d = 5 # Dimension del problema\n",
    "w = np.random.randn(1, d)\n",
    "b = 1.0\n",
    "xmin = 0.0\n",
    "xmax = 10.0\n",
    "noise = 1.0\n",
    "n = 1000\n",
    "\n",
    "# Datos del problema generados al azar:\n",
    "x = xmin + np.random.rand(n, d)*(xmax - xmin)\n",
    "t0 = np.dot(x, w.T) + b \n",
    "t = t0 + np.random.randn(n, 1)*noise\n",
    "tmin = np.min(t)\n",
    "tmax = np.max(t)\n",
    "\n",
    "# Distribucion de las dos primeras variables:\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.subplot(121)\n",
    "plt.plot(x[:, 0], x[:, 1], 'o')\n",
    "plt.grid(True)\n",
    "plt.xlabel(\"x1\")\n",
    "plt.ylabel(\"x2\")\n",
    "plt.subplot(122)\n",
    "\n",
    "# Grafica de t frente a t0:\n",
    "plt.plot(t0, t, 'o')\n",
    "plt.plot([tmin, tmax], [tmin, tmax], 'r-')\n",
    "plt.grid(True)\n",
    "plt.xlabel(\"t0\")\n",
    "plt.ylabel(\"t\")\n",
    "plt.show()\n",
    "\n",
    "# Error esperado:\n",
    "e = np.sum((t-t0)*(t-t0))\n",
    "print(\"Error esperado = %f\" % e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nax9A91aaNc0"
   },
   "source": [
    "Forma de los vectores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1684484199836,
     "user": {
      "displayName": "christian oliva moya",
      "userId": "04396812984644697862"
     },
     "user_tz": -120
    },
    "id": "CGYdnMLDZ4nG",
    "outputId": "1b556d94-cb04-4a6c-f26a-380fda06da88"
   },
   "outputs": [],
   "source": [
    "print(x.shape)\n",
    "print(t.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WRgATzqpad5m"
   },
   "source": [
    "Modelo de regresión lineal con los parámetros inicializados al azar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 560
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1684484199836,
     "user": {
      "displayName": "christian oliva moya",
      "userId": "04396812984644697862"
     },
     "user_tz": -120
    },
    "id": "YrbCLsvPaTRI",
    "outputId": "464ececd-b7a1-49f6-f13f-b23e70e29e1b"
   },
   "outputs": [],
   "source": [
    "w = np.random.randn(1, d)\n",
    "b = np.random.randn()\n",
    "\n",
    "# Aplico el modelo a los datos y comparo la prediccion y con el objetivo t:\n",
    "y = np.dot(x, w.T) + b\n",
    "\n",
    "# Grafica de y frente a t:\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.plot(t, y, 'o')\n",
    "plt.plot([tmin, tmax], [tmin, tmax], 'r-')\n",
    "plt.grid(True)\n",
    "plt.xlabel(\"t\")\n",
    "plt.ylabel(\"y\")\n",
    "plt.show()\n",
    "\n",
    "# Error:\n",
    "e = np.sum((y-t)*(y-t))  \n",
    "print(\"Error = %f\" % e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ad_HnpDMas0N"
   },
   "source": [
    "Entrenamiento del modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 4728,
     "status": "ok",
     "timestamp": 1684484204557,
     "user": {
      "displayName": "christian oliva moya",
      "userId": "04396812984644697862"
     },
     "user_tz": -120
    },
    "id": "iAWYGrCDah2I",
    "outputId": "d81bc435-cc66-4c5b-cb8a-81dd43daa699"
   },
   "outputs": [],
   "source": [
    "nepocas = 64\n",
    "eta = 0.000005\n",
    "\n",
    "plt.figure(figsize=(16,16))\n",
    "\n",
    "k = 1\n",
    "error = []\n",
    "for epoch in range(nepocas):\n",
    "    y = np.dot(x, w.T) + b\n",
    "    \n",
    "    #----------------------------------------------------------\n",
    "    # TO-DO: Calcula el error:\n",
    "    e = 0 # TO-DO actualiza el error\n",
    "    error.append(e)\n",
    "    #----------------------------------------------------------\n",
    "\n",
    "    if epoch%4 == 0:\n",
    "        plt.subplot(4, 4, k)\n",
    "        plt.plot(t, y, 'o')\n",
    "        plt.plot([tmin, tmax], [tmin, tmax], 'r-')\n",
    "        plt.grid(True)\n",
    "        plt.title(\"epoca = %d, err = %.2f\" % (epoch, e))\n",
    "        k += 1\n",
    "        \n",
    "    #----------------------------------------------------------\n",
    "    # TO-DO: Calcula los gradientes y actualiza los parametros:    \n",
    "    \n",
    "    b = b # TO-DO actualiza los parámetros\n",
    "    w = w # TO-DO actualiza los parámetros\n",
    "    #----------------------------------------------------------\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "93E3pGM5a51W"
   },
   "source": [
    "Error frente a número de épocas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 445
    },
    "executionInfo": {
     "elapsed": 24,
     "status": "ok",
     "timestamp": 1684484204559,
     "user": {
      "displayName": "christian oliva moya",
      "userId": "04396812984644697862"
     },
     "user_tz": -120
    },
    "id": "nzR5BJdWaubX",
    "outputId": "9224bd94-2735-43e4-9cce-6f233f362b3a"
   },
   "outputs": [],
   "source": [
    "plt.plot(range(nepocas), error)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7uwP6KLQc2qn"
   },
   "source": [
    "# California Housing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "California Housing contiene información sobre viviendas en distintas áreas de California, basada en el censo de 1990. El objetivo consiste en predecir el valor medio de las viviendas en cada área. Los atributos son los siguientes:\n",
    "\n",
    "* **MedInc**: Ingreso medio de los hogares dentro de un área\n",
    "\n",
    "* **HouseAge**: Edad media de una vivienda dentro de un área\n",
    "\n",
    "* **AveRooms**: Promedio de habitaciones en una vivienda dentro de un área\n",
    "\n",
    "* **AveBedrms**: Promedio de dormitorios en una vivienda dentro de un área\n",
    "\n",
    "* **Population**: Población en el área\n",
    "\n",
    "* **AveOccup**: Tamaño de familia promedio en el área\n",
    "\n",
    "* **Latitude**: Latitud\n",
    "\n",
    "* **Longitude**: Longitud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 268,
     "status": "ok",
     "timestamp": 1684485749775,
     "user": {
      "displayName": "christian oliva moya",
      "userId": "04396812984644697862"
     },
     "user_tz": -120
    },
    "id": "HgfkFCxOc4jR",
    "outputId": "8493eaa3-69c7-450e-ff2d-b58803e489e0"
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "\n",
    "x, t = fetch_california_housing(return_X_y=True, as_frame=True)\n",
    "print(x.shape)\n",
    "print(t.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separamos en train - test para evaluar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, t, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"TRAIN\", x_train.shape, y_train.shape)\n",
    "print(\"TEST\", x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Guhb2FZlSqSt"
   },
   "source": [
    "Estandarizamos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RKz0eODfSvOJ"
   },
   "outputs": [],
   "source": [
    "# Estandarizar los datos:\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "sc = StandardScaler()\n",
    "x_train = sc.fit_transform(x_train)\n",
    "x_test = sc.transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1gLrOZoRRdSP"
   },
   "source": [
    "Nos quedamos sólo con los primeros 1000 ejemplos para que las ejecuciones sean más rápidas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1684485749973,
     "user": {
      "displayName": "christian oliva moya",
      "userId": "04396812984644697862"
     },
     "user_tz": -120
    },
    "id": "yPx-zvLLRfuZ",
    "outputId": "f6a77d7e-62c5-4324-b736-2d93f13a9a85"
   },
   "outputs": [],
   "source": [
    "x_train = x_train[:1000]\n",
    "y_train = y_train[:1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZWBjllTLeCNn"
   },
   "source": [
    "Construye un modelo de regresión lineal para predecir la variable $t$ a partir de los atributos $x$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yKvai5ojitYR"
   },
   "outputs": [],
   "source": [
    "d = x.shape[1]\n",
    "\n",
    "w = np.random.randn(1, d)\n",
    "b = np.random.randn()\n",
    "\n",
    "nepocas = 400\n",
    "eta = 0.0001\n",
    "\n",
    "k = 1\n",
    "error = []\n",
    "for i in range(nepocas):\n",
    "    pred = np.dot(x_train, w.T) + b\n",
    "    pred = pred[:, 0]\n",
    "    \n",
    "    #----------------------------------------------------------\n",
    "    # TO-DO: Calcula el error:\n",
    "    e = 0 # TO-DO actualiza el error\n",
    "    error.append(e)\n",
    "    #----------------------------------------------------------\n",
    "\n",
    "    #----------------------------------------------------------\n",
    "    # TO-DO: Calcula los gradientes y actualiza los parametros:    \n",
    "    \n",
    "    b = b # TO-DO actualiza los parámetros\n",
    "    w = w # TO-DO actualiza los parámetros\n",
    "    #----------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 430
    },
    "executionInfo": {
     "elapsed": 328,
     "status": "ok",
     "timestamp": 1684485752276,
     "user": {
      "displayName": "christian oliva moya",
      "userId": "04396812984644697862"
     },
     "user_tz": -120
    },
    "id": "6_qbIXmClZix",
    "outputId": "0313bebc-bd30-4bdf-e3ec-e75b5b3d7c55"
   },
   "outputs": [],
   "source": [
    "plt.plot(range(nepocas), error)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 560
    },
    "executionInfo": {
     "elapsed": 818,
     "status": "ok",
     "timestamp": 1684485753764,
     "user": {
      "displayName": "christian oliva moya",
      "userId": "04396812984644697862"
     },
     "user_tz": -120
    },
    "id": "BFzKmKyKrnud",
    "outputId": "f80e1ad3-988a-4849-a87b-d70ec04ef65f",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Aplico el modelo a los datos y comparo la prediccion y con el objetivo t:\n",
    "pred = np.dot(x_test, w.T) + b\n",
    "pred = pred[:, 0]\n",
    "\n",
    "# Grafica de y frente a t:\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.plot(y_test, pred, 'o')\n",
    "plt.plot([0, 6], [0, 6], 'r-')\n",
    "plt.grid(True)\n",
    "plt.xlabel(\"y_test\")\n",
    "plt.ylabel(\"pred\")\n",
    "plt.show()\n",
    "\n",
    "# Error:\n",
    "e = np.mean((pred-y_test)*(pred-y_test))  \n",
    "print(\"Error = %f\" % e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6vfepGOjVigB"
   },
   "source": [
    "## Comprobación de California Housing con otras alternativas\n",
    "\n",
    "Vamos a comprobarlo con la regresión lineal implementada con Sklearn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S94yIfTMVYyF"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SrwPMPXCWKO2"
   },
   "source": [
    "### Opción 1: Regresión lineal siguiendo la estrategia de mínimos cuadrados\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DrdPe1gIVe5X"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1684485754503,
     "user": {
      "displayName": "christian oliva moya",
      "userId": "04396812984644697862"
     },
     "user_tz": -120
    },
    "id": "jAAX4yEQVdjm",
    "outputId": "208ffab5-9387-473b-afdd-83dfa7b121fc"
   },
   "outputs": [],
   "source": [
    "lr = LinearRegression().fit(x_train, y_train)\n",
    "pred = lr.predict(x_train)\n",
    "print(\"TRAIN:\", mean_squared_error(y_train, pred))\n",
    "pred = lr.predict(x_test)\n",
    "print(\"TEST:\", mean_squared_error(y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6iYZ33k2WcFj"
   },
   "source": [
    "### Opción 2: Regresión lineal siguiendo la estrategia de minimización mediante descenso por gradiente (SGD)\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDRegressor.html#sklearn.linear_model.SGDRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HBUJQBNlVzFF"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1684485756223,
     "user": {
      "displayName": "christian oliva moya",
      "userId": "04396812984644697862"
     },
     "user_tz": -120
    },
    "id": "QAg3en1jXAZ9",
    "outputId": "aa03cb0a-7f17-4d10-ce45-1a6d6f911598"
   },
   "outputs": [],
   "source": [
    "lr = SGDRegressor(penalty=None).fit(x_train, y_train)\n",
    "pred = lr.predict(x_train)\n",
    "print(\"TRAIN:\", mean_squared_error(y_train, pred))\n",
    "pred = lr.predict(x_test)\n",
    "print(\"TEST:\", mean_squared_error(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1684485756223,
     "user": {
      "displayName": "christian oliva moya",
      "userId": "04396812984644697862"
     },
     "user_tz": -120
    },
    "id": "OnoSmTFBHRQ_",
    "outputId": "261a2c32-a65a-4388-df90-999bf4c6708d"
   },
   "outputs": [],
   "source": [
    "# La variable coef_ representa los pesos de cada atributo\n",
    "lr.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1684485756223,
     "user": {
      "displayName": "christian oliva moya",
      "userId": "04396812984644697862"
     },
     "user_tz": -120
    },
    "id": "A1AF3AgwHalM",
    "outputId": "a854bfb8-7a90-4104-c366-81f40ce1fcaf"
   },
   "outputs": [],
   "source": [
    "# La variable intercept_ representa el bias\n",
    "lr.intercept_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mWlisovrGpt2"
   },
   "source": [
    "## Probemos la regresión lineal con regularización L1 o L2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PUtgGEUEGzYS"
   },
   "source": [
    "### Regularización Ridge (L2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1zUHpod-Jvqu"
   },
   "source": [
    "La clase ```SGDRegressor``` implementa la opción de penalizar tanto con L1 como con L2 el entrenamiento de descenso por gradiente. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 311,
     "status": "ok",
     "timestamp": 1684485758358,
     "user": {
      "displayName": "christian oliva moya",
      "userId": "04396812984644697862"
     },
     "user_tz": -120
    },
    "id": "b8S0P_pwHmP7",
    "outputId": "a34f43e9-013b-4ec9-e285-73d8396786a0"
   },
   "outputs": [],
   "source": [
    "lr = SGDRegressor(penalty='l2', alpha=0.1).fit(x_train, y_train)\n",
    "pred = lr.predict(x_train)\n",
    "print(\"TRAIN:\", mean_squared_error(y_train, pred))\n",
    "pred = lr.predict(x_test)\n",
    "print(\"TEST:\", mean_squared_error(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1684485758359,
     "user": {
      "displayName": "christian oliva moya",
      "userId": "04396812984644697862"
     },
     "user_tz": -120
    },
    "id": "b2P6c3a9H6i2",
    "outputId": "b6b59c7e-8929-43b3-e0ff-32cc5c7c0e06"
   },
   "outputs": [],
   "source": [
    "# La variable coef_ guarda todos los pesos de la regresión\n",
    "lr.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1684485758360,
     "user": {
      "displayName": "christian oliva moya",
      "userId": "04396812984644697862"
     },
     "user_tz": -120
    },
    "id": "p74qNUoYIBNf",
    "outputId": "9a4af623-fe92-413f-a529-5efe57ce4356"
   },
   "outputs": [],
   "source": [
    "# La variable intercept_ guarda el bias\n",
    "lr.intercept_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SK0SvNYtJ6TG"
   },
   "source": [
    "Pintemos los pesos de los atributos con un diagrama de barras. Así podremos saber qué \"importancia\" le da nuestro modelo a los atributos de entrada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 449
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1684485760065,
     "user": {
      "displayName": "christian oliva moya",
      "userId": "04396812984644697862"
     },
     "user_tz": -120
    },
    "id": "UBpxBjrNI70z",
    "outputId": "7b00719f-ca0d-4c87-fe8c-7575dedb9a4b"
   },
   "outputs": [],
   "source": [
    "plt.bar(np.arange(len(lr.coef_)), lr.coef_)\n",
    "plt.xlabel(\"Attribute ID\")\n",
    "plt.ylabel(\"Weight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OBiuzHxYKUp5"
   },
   "source": [
    "Veamos ahora el error frente al factor alpha de regularización L2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mfj4o4PAIB3G"
   },
   "outputs": [],
   "source": [
    "l2_values = [0.0, 1e-6, 1e-5, 1e-4, 1e-3, 1e-2, 1e-1, 1.0]\n",
    "errores = []\n",
    "for l2 in l2_values:\n",
    "    lr = SGDRegressor(penalty='l2', alpha=l2).fit(x_train, y_train)\n",
    "    pred = lr.predict(x_test)\n",
    "    e = mean_squared_error(y_test, pred)\n",
    "    errores.append(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 450
    },
    "executionInfo": {
     "elapsed": 353,
     "status": "ok",
     "timestamp": 1684485762378,
     "user": {
      "displayName": "christian oliva moya",
      "userId": "04396812984644697862"
     },
     "user_tz": -120
    },
    "id": "8Jd8dWBEIpG-",
    "outputId": "6d313aed-6d8f-464a-fd85-37bc78f5015c"
   },
   "outputs": [],
   "source": [
    "plt.plot(errores, '.-')\n",
    "plt.xticks(np.arange(len(l2_values)), l2_values)\n",
    "plt.xlabel(\"Factor de regularización L2\")\n",
    "plt.ylabel(\"MSE\")\n",
    "plt.show()\n",
    "\n",
    "# En la figura vemos que cuanto mayor penalización damos a los pesos, mayor es el MSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fyP5NIFRKmnZ"
   },
   "source": [
    "### Regularización Lasso (L1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k_ij1JflKtAz"
   },
   "source": [
    "La clase ```SGDRegressor``` implementa la opción de penalizar tanto con L1 como con L2 el entrenamiento de descenso por gradiente. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 196,
     "status": "ok",
     "timestamp": 1684485763466,
     "user": {
      "displayName": "christian oliva moya",
      "userId": "04396812984644697862"
     },
     "user_tz": -120
    },
    "id": "njpzN168Iqxy",
    "outputId": "2506b48f-65a5-485c-d457-8cbe1e2b9be1"
   },
   "outputs": [],
   "source": [
    "lr = SGDRegressor(penalty='l1', alpha=0.1).fit(x_train, y_train)\n",
    "pred = lr.predict(x_test)\n",
    "mean_squared_error(y_test, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1WIsnPn8Kz-M"
   },
   "source": [
    "Pintemos los pesos de los atributos con un diagrama de barras. Así podremos saber qué \"importancia\" le da nuestro modelo a los atributos de entrada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 449
    },
    "executionInfo": {
     "elapsed": 762,
     "status": "ok",
     "timestamp": 1684485764541,
     "user": {
      "displayName": "christian oliva moya",
      "userId": "04396812984644697862"
     },
     "user_tz": -120
    },
    "id": "N84Ko1oeKvTU",
    "outputId": "821060d3-4af6-4f4f-f019-9478aa255869"
   },
   "outputs": [],
   "source": [
    "plt.bar(np.arange(len(lr.coef_)), lr.coef_)\n",
    "plt.xlabel(\"Attribute ID\")\n",
    "plt.ylabel(\"Weight\")\n",
    "plt.show()\n",
    "\n",
    "# Con la regularización L1 (mucho más agresiva que la L2) vemos como los pesos de algunos atributos tienden a 0, \n",
    "# es decir, el modelo aprende a realizar una selección de características de entrada."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "etVhLe_0K9kV"
   },
   "source": [
    "Veamos ahora el error frente al factor alpha de regularización L1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S_gd_pDiK1nT"
   },
   "outputs": [],
   "source": [
    "l1_values = [0.0, 1e-6, 1e-5, 1e-4, 1e-3, 1e-2, 1e-1, 1.0]\n",
    "errores = []\n",
    "for l1 in l1_values:\n",
    "    lr = SGDRegressor(penalty='l1', alpha=l1).fit(x_train, y_train)\n",
    "    pred = lr.predict(x_test)\n",
    "    e = mean_squared_error(y_test, pred)\n",
    "    errores.append(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 450
    },
    "executionInfo": {
     "elapsed": 294,
     "status": "ok",
     "timestamp": 1684485769708,
     "user": {
      "displayName": "christian oliva moya",
      "userId": "04396812984644697862"
     },
     "user_tz": -120
    },
    "id": "aTe4u7uaLMc5",
    "outputId": "bcc76f06-cfe1-4746-9c4f-6f5aff6f9896"
   },
   "outputs": [],
   "source": [
    "plt.plot(errores, '.-')\n",
    "plt.xticks(np.arange(len(l1_values)), l1_values)\n",
    "plt.xlabel(\"Factor de regularización L1\")\n",
    "plt.ylabel(\"MSE\")\n",
    "plt.show()\n",
    "\n",
    "# En la figura vemos que cuanto mayor penalización damos a los pesos, mayor es el MSE\n",
    "# Ojo en la escala. Fíjate además como L1, comparada con L2, es más agresiva."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ElasticNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La clase ```SGDRegressor``` implementa la opción de penalizar tanto con L1 como con L2 el entrenamiento de descenso por gradiente. Si quieres combinar ambas regularizaciones, tienes la opción de utilizar la configuración *ElasticNet*, cuya penalización se expresa de la siguiente manera:\n",
    "\n",
    "$$Penalización ElasticNet = \\alpha (\\phi L1 + (1 - \\phi) L2)$$\n",
    "\n",
    "donde $\\alpha$ es el factor de regularización (parámetro `alpha`) y $\\phi$ es el parámetro que define la contribución de las penalizaciones (parámetro `l1_ratio`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = SGDRegressor(penalty='elasticnet', alpha=0.1, l1_ratio=0.15).fit(x_train, y_train)\n",
    "pred = lr.predict(x_test)\n",
    "mean_squared_error(y_test, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejercicio**: Busca la mejor configuración posible combinando los hiperparámetros alpha y l1_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------------------------------------------------------\n",
    "# TO-DO: Define los posibles valores de alpha y l1_ratio a buscar\n",
    "ratio_values = []\n",
    "alpha_values = []\n",
    "#------------------------------------------------------------------\n",
    "\n",
    "errores = []\n",
    "#------------------------------------------------------------------\n",
    "# TO-DO: Construye un bucle para probar todas las posibilidades\n",
    "\n",
    "#------------------------------------------------------------------\n",
    "\n",
    "errores = np.array(errores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(errores)\n",
    "plt.xticks(range(len(ratio_values)), np.around(ratio_values, 2), rotation=90)\n",
    "plt.xlabel(\"Ratio L1 (phi)\")\n",
    "plt.yticks(range(len(alpha_values)), alpha_values)\n",
    "plt.ylabel(\"Regularization penalty (alpha)\")\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "print(\"MIN ERROR:\", errores.min())\n",
    "print(\"ALPHA:\", alpha_values[np.where(errores == errores.min())[0][0]])\n",
    "print(\"RATIO:\", ratio_values[np.where(errores == errores.min())[1][0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pUDbIuQ5LVm2"
   },
   "source": [
    "## ¿Y si utilizamos métodos de Kernel para buscar transformaciónes no lineales?\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.kernel_ridge.KernelRidge.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mzhBA79lOyBX"
   },
   "outputs": [],
   "source": [
    "from sklearn.kernel_ridge import KernelRidge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 207,
     "status": "ok",
     "timestamp": 1684485775448,
     "user": {
      "displayName": "christian oliva moya",
      "userId": "04396812984644697862"
     },
     "user_tz": -120
    },
    "id": "hAkrajXpPDcR",
    "outputId": "7eb809b6-323e-477e-b960-c88cfd2aa8cd"
   },
   "outputs": [],
   "source": [
    "lr = KernelRidge(alpha=0.1, kernel='rbf', gamma=None).fit(x_train, y_train)\n",
    "pred = lr.predict(x_test)\n",
    "mean_squared_error(y_test, pred)\n",
    "\n",
    "# Al encontrar transformaciones no lineales, el modelo obtiene un error mucho menor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xSs5Jr_rMzr6"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
